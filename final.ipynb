{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce7521f3",
   "metadata": {},
   "source": [
    "# Tudo junto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec025c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --quiet langchain_milvus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50ae825a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rondi\\Desktop\\PROGRAMACAO\\INTELIGENCIA ARTIFICIAL\\LANG-CHAIN - AVANCADO\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from transformers import AutoTokenizer\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_milvus import Milvus\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, CommaSeparatedListOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain_classic.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd3da9c",
   "metadata": {},
   "source": [
    "## Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dd04220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No languages specified, defaulting to English.\n",
      "Warning: No languages specified, defaulting to English.\n",
      "Warning: No languages specified, defaulting to English.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdfs = DirectoryLoader(\"documentos\", glob=\"*.pdf\").load()\n",
    "len(pdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb631183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_model = \"BAAI/bge-m3\"\n",
    "embeddings_tokenizer = AutoTokenizer.from_pretrained(embeddings_model)\n",
    "\n",
    "splitter = CharacterTextSplitter.from_huggingface_tokenizer(\n",
    "    tokenizer=embeddings_tokenizer,\n",
    "    chunk_size=1250, chunk_overlap=150\n",
    ")\n",
    "\n",
    "pedacos = splitter.split_documents(pdfs)\n",
    "len(pedacos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b50419d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'documentos\\\\GTB_gold_Nov23.pdf'}, page_content=\"Compras Cobertas feitas a partir de 1º de maio de 2021 não estarão sujeitas à lista dos “Bens Elegíveis a este Seguro” abaixo.\\n\\nVersão: novembro 2023 2021\\n\\n9\\n\\nA cobertura está sujeita a termos, condições e exclusões aplicáveis.\\n\\nBens Elegíveis a este Seguro (válido SOMENTE para compras feitas em ou antes de 30 de abril de 2021): Áudio Portátil / Áudio System / Auto Rádio, DVD Player, Karaokê, Videokê, Blue ray, GPS, Home theater com ou sem dvd e blu-ray, Filmadora Digital, Lente para máquina fotográfica e para celulares, Máquina fotográfica digital, MP3 Player, MP4 Player, MP5 Player, iPod, Dock Station, Receptor / Decodificador / Conversor de sinal digital, Telão de Projeção ou Datashow, Televisor Convencional / LCD / LED, Televisor de Plasma, Vídeo Game, Tênis / Sapatênis / Sapato / Chinelos / Sandálias / Botas, Ar Condicionado Janela / Split / Portátil, Bebedouro de Água Elétrico ou Purificador de Água Elétrico, Coifa / Depurador de Ar, Fogão convencional a gás ou Cooktop / Forno a Gás ou Elético / Microondas, Lavadora de Alta Pressão, Lavadora de Louças, Lavadora de Roupas / Tanquinho / Secadora de Roupas / Centrífuga de Roupas / Lava e Seca, Máquina de Costura, Refrigerador 1 porta ou 2 portas / Frigobar / Freezer / Adega / Cave de Vinhos / Cervejeira, Refrigerador side by side, Alisador de cabelo ou pranchinha / Escova de cabelo elétrica / Depilador / Secador de cabelo / Modelador e ondulador de cabelo / Pedicuro elétrico, Aquecedor de ar elétrico e a gás, Aspirador de pó ou água / Enceradeira / Vassoura elétrica / Ferro de passar roupa, Cafeteira / Máquina de Café Expresso / Suporte refrigerado para água, Climatizador / Umidificador / Desumidificador / Purificador de Ar / Inalador / Nebulizador, Chuveiro elétrico / Bomba d'água elétrica, Faca elétrica / Fatiador / Jarra elétrica / Sanduicheira / Waffer / Grill / Churrasqueira Elétrica / Tostador e Torradeira de pão / Balança digital, Máquina de fazer pão doméstica / Batedeira Elétrica / Fritadeira elétrica e a gás / Panela elétrica / Cozedor a vapor, Medidor de pressão / Massageador, Multiprocessador / Processador / Centrífuga de frutas / Espremedor de frutas / Liquidificador / Mixer / Iogurteira / Sorveteira, Telefone com e sem Fio, Ventilador de ar de mesa, teto e pé / Circulador de Ar, Webcam / Mouse / Rádio relógio / Agenda Eletrônica / Calculadora / Teclado de computador / Microfone para computador, Bicicleta, Bicicleta ergométrica, Remo, Elíptico, Esteira mecânica ou elétrica, Mala / Mochila / Bolsa, Raquete de tênis / Raquete de Badminton / Raquete de tênis de mesa / Taco de Bilhar / Taco de Golfe / Taco de Hóquei / Taco de Beisebol, Skate / Patins / Patinete, Aparador de Grama Elétrico / Cortador de grama a gasolina / Soprador Térmico / Soprador a gasolina / Sugador / Soprador Elétrico / Tesoura Multi Cutter, Furadeira Elétrica / Furadeira de Impacto / Lixadeira Elétrica / Martelete Elétrico / Parafusadeira Elétrica / Plaina Elétrica / Tupia, Micro Retífica Elétrica / Multi Estação Elétrica / Politriz Elétrica / Roçadeira Elétrica / Motosserra, Serra de Fita Elétrica / Serra Mesa Elétrica / Serra Mármore Elétrica / Serra Tico Tico Elétrica / Serra Circular Elétrica / Esmirilhadeira, Brinquedos, Cadeira e assento para carro, Carrinho de bebê, Computador Desktop e All in One, Impressora jato de Tinta, Multifuntional, Laser / Scanner, Monitor de tubo convencional, LCD e LED, Laptop / Notebook / Netbook / Tablet / E-reader (Kindle), Afinador, Braçadeira, Capodastro, Fone de ouvido, Aparelho de iluminação (Luminária), Máquina de Fumaça, Metrônomo, Baixo, Baixolão, Bandolin, Banjo, Cavaco, Guitarra Elétrica, Viola, Violino e Violoncelo, Caixas, Cubos, Amplificadores, Equalizadores, Woofer (alto falante) e Super Tweeter, Misturador, Mixer, Microfones, Pedais e Pedaleiras, Teclado Musical, Armário / Estante / Gabinete / Guarda-roupa / Penteadeira / Rack / Passadeira / Paneleiro / Bar / Cômoda / Criado Mudo, Cadeira estofada / Cadeira de madeira / Poltrona / Sofá / Sofá Cama / Cama, Colchões, Mesa madeira, metal ou vidro / Mesa de Computador / Mesa de Pedra / Mesa para Jardim, Óculos de sol e de prescrição, Relógio convencional, Smart Watches, Telefone Celular / Smartphone, Roupas.\")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pedacos[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcd3a1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymilvus[milvus_lite] in c:\\users\\rondi\\desktop\\programacao\\inteligencia artificial\\lang-chain - avancado\\venv\\lib\\site-packages (2.6.3)\n",
      "Requirement already satisfied: setuptools>69 in c:\\users\\rondi\\desktop\\programacao\\inteligencia artificial\\lang-chain - avancado\\venv\\lib\\site-packages (from pymilvus[milvus_lite]) (80.9.0)\n",
      "Requirement already satisfied: grpcio!=1.68.0,!=1.68.1,!=1.69.0,!=1.70.0,!=1.70.1,!=1.71.0,!=1.72.1,!=1.73.0,>=1.66.2 in c:\\users\\rondi\\desktop\\programacao\\inteligencia artificial\\lang-chain - avancado\\venv\\lib\\site-packages (from pymilvus[milvus_lite]) (1.76.0)\n",
      "Requirement already satisfied: orjson>=3.10.15 in c:\\users\\rondi\\desktop\\programacao\\inteligencia artificial\\lang-chain - avancado\\venv\\lib\\site-packages (from pymilvus[milvus_lite]) (3.11.4)\n",
      "Requirement already satisfied: protobuf>=5.27.2 in c:\\users\\rondi\\desktop\\programacao\\inteligencia artificial\\lang-chain - avancado\\venv\\lib\\site-packages (from pymilvus[milvus_lite]) (6.33.1)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in c:\\users\\rondi\\desktop\\programacao\\inteligencia artificial\\lang-chain - avancado\\venv\\lib\\site-packages (from pymilvus[milvus_lite]) (1.2.1)\n",
      "Requirement already satisfied: pandas>=1.2.4 in c:\\users\\rondi\\desktop\\programacao\\inteligencia artificial\\lang-chain - avancado\\venv\\lib\\site-packages (from pymilvus[milvus_lite]) (2.3.3)\n",
      "Requirement already satisfied: typing-extensions~=4.12 in c:\\users\\rondi\\desktop\\programacao\\inteligencia artificial\\lang-chain - avancado\\venv\\lib\\site-packages (from grpcio!=1.68.0,!=1.68.1,!=1.69.0,!=1.70.0,!=1.70.1,!=1.71.0,!=1.72.1,!=1.73.0,>=1.66.2->pymilvus[milvus_lite]) (4.15.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\rondi\\desktop\\programacao\\inteligencia artificial\\lang-chain - avancado\\venv\\lib\\site-packages (from pandas>=1.2.4->pymilvus[milvus_lite]) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rondi\\desktop\\programacao\\inteligencia artificial\\lang-chain - avancado\\venv\\lib\\site-packages (from pandas>=1.2.4->pymilvus[milvus_lite]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rondi\\desktop\\programacao\\inteligencia artificial\\lang-chain - avancado\\venv\\lib\\site-packages (from pandas>=1.2.4->pymilvus[milvus_lite]) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rondi\\desktop\\programacao\\inteligencia artificial\\lang-chain - avancado\\venv\\lib\\site-packages (from pandas>=1.2.4->pymilvus[milvus_lite]) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rondi\\desktop\\programacao\\inteligencia artificial\\lang-chain - avancado\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.2.4->pymilvus[milvus_lite]) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymilvus[milvus_lite]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e411e57",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionConfigException",
     "evalue": "<ConnectionConfigException: (code=1, message=milvus-lite is required for local database connections. Please install it with: pip install pymilvus[milvus_lite])>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rondi\\Desktop\\PROGRAMACAO\\INTELIGENCIA ARTIFICIAL\\LANG-CHAIN - AVANCADO\\venv\\Lib\\site-packages\\pymilvus\\orm\\connections.py:382\u001b[39m, in \u001b[36mConnections.connect\u001b[39m\u001b[34m(self, alias, user, password, db_name, token, _async, **kwargs)\u001b[39m\n\u001b[32m    381\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m382\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmilvus_lite\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mserver_manager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    383\u001b[39m         server_manager_instance,\n\u001b[32m    384\u001b[39m     )\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'milvus_lite'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mConnectionConfigException\u001b[39m                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m embeddings_model = OllamaEmbeddings(model=\u001b[33m\"\u001b[39m\u001b[33mbge-m3:567m\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m URI = \u001b[33m\"\u001b[39m\u001b[33m./milvus_example.db\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m vector_store = \u001b[43mMilvus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_function\u001b[49m\u001b[43m=\u001b[49m\u001b[43membeddings_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconnection_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muri\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mURI\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mindex_type\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mFLAT\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetric_type\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mL2\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rondi\\Desktop\\PROGRAMACAO\\INTELIGENCIA ARTIFICIAL\\LANG-CHAIN - AVANCADO\\venv\\Lib\\site-packages\\langchain_milvus\\vectorstores\\milvus.py:377\u001b[39m, in \u001b[36mMilvus.__init__\u001b[39m\u001b[34m(self, embedding_function, collection_name, collection_description, collection_properties, connection_args, consistency_level, index_params, search_params, drop_old, auto_id, primary_field, text_field, vector_field, enable_dynamic_field, metadata_field, partition_key_field, num_partitions, partition_names, replica_number, timeout, num_shards, vector_schema, metadata_schema, builtin_function)\u001b[39m\n\u001b[32m    374\u001b[39m \u001b[38;5;66;03m# Store connection args for potential async client creation\u001b[39;00m\n\u001b[32m    375\u001b[39m \u001b[38;5;28mself\u001b[39m._connection_args = connection_args\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m \u001b[38;5;28mself\u001b[39m._milvus_client = \u001b[43mMilvusClient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mconnection_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[38;5;66;03m# Safely create AsyncMilvusClient to avoid failures in multithreading\u001b[39;00m\n\u001b[32m    382\u001b[39m \u001b[38;5;66;03m# environments\u001b[39;00m\n\u001b[32m    383\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rondi\\Desktop\\PROGRAMACAO\\INTELIGENCIA ARTIFICIAL\\LANG-CHAIN - AVANCADO\\venv\\Lib\\site-packages\\pymilvus\\milvus_client\\milvus_client.py:67\u001b[39m, in \u001b[36mMilvusClient.__init__\u001b[39m\u001b[34m(self, uri, user, password, db_name, token, timeout, **kwargs)\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m     45\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     46\u001b[39m     uri: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mhttp://localhost:19530\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     52\u001b[39m     **kwargs,\n\u001b[32m     53\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     54\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"A client for the common Milvus use case.\u001b[39;00m\n\u001b[32m     55\u001b[39m \n\u001b[32m     56\u001b[39m \u001b[33;03m    This client attempts to hide away the complexity of using Pymilvus. In a lot ofcases what\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     65\u001b[39m \u001b[33;03m            Unit: second\u001b[39;00m\n\u001b[32m     66\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     \u001b[38;5;28mself\u001b[39m._using = \u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m        \u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     70\u001b[39m     \u001b[38;5;28mself\u001b[39m.is_self_hosted = \u001b[38;5;28mbool\u001b[39m(utility.get_server_type(using=\u001b[38;5;28mself\u001b[39m._using) == \u001b[33m\"\u001b[39m\u001b[33mmilvus\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rondi\\Desktop\\PROGRAMACAO\\INTELIGENCIA ARTIFICIAL\\LANG-CHAIN - AVANCADO\\venv\\Lib\\site-packages\\pymilvus\\milvus_client\\_utils.py:43\u001b[39m, in \u001b[36mcreate_connection\u001b[39m\u001b[34m(uri, token, db_name, use_async, user, password, **kwargs)\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m connections.has_connection(using):\n\u001b[32m     41\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m using\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m \u001b[43mconnections\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43musing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muri\u001b[49m\u001b[43m=\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_async\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_async\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m logger.debug(\u001b[33m\"\u001b[39m\u001b[33mCreated new connection using: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, using)\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m using\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rondi\\Desktop\\PROGRAMACAO\\INTELIGENCIA ARTIFICIAL\\LANG-CHAIN - AVANCADO\\venv\\Lib\\site-packages\\pymilvus\\orm\\connections.py:386\u001b[39m, in \u001b[36mConnections.connect\u001b[39m\u001b[34m(self, alias, user, password, db_name, token, _async, **kwargs)\u001b[39m\n\u001b[32m    382\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmilvus_lite\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mserver_manager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    383\u001b[39m         server_manager_instance,\n\u001b[32m    384\u001b[39m     )\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m386\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ConnectionConfigException(\n\u001b[32m    387\u001b[39m         message=\u001b[33m\"\u001b[39m\u001b[33mmilvus-lite is required for local database connections. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    388\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease install it with: pip install pymilvus[milvus_lite]\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    389\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    391\u001b[39m local_uri = server_manager_instance.start_and_get_uri(kwargs[\u001b[33m\"\u001b[39m\u001b[33muri\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    392\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m local_uri \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mConnectionConfigException\u001b[39m: <ConnectionConfigException: (code=1, message=milvus-lite is required for local database connections. Please install it with: pip install pymilvus[milvus_lite])>"
     ]
    }
   ],
   "source": [
    "embeddings_model = OllamaEmbeddings(model=\"bge-m3:567m\")\n",
    "\n",
    "URI = \"./milvus_example.db\"\n",
    "\n",
    "vector_store = Milvus(\n",
    "    embedding_function=embeddings_model,\n",
    "    connection_args={\"uri\": URI},\n",
    "    index_params={\"index_type\": \"FLAT\", \"metric_type\": \"L2\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d7e247",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.add_documents(pedacos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d06874",
   "metadata": {},
   "source": [
    "## Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70c223b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_model = OllamaLLM(model=\"gemma3:1b\")\n",
    "\n",
    "# multi_query_prompt_template = \"\"\"Você é um assistente de modelo de linguagem de IA. Sua tarefa é gerar cinco\n",
    "# versões diferentes da pergunta do usuário para recuperar documentos relevantes de um banco de dados vetorial.\n",
    "# Ao gerar múltiplas perspectivas sobre a pergunta do usuário, seu objetivo é ajudar\n",
    "# o usuário a superar algumas das limitações da busca por similaridade baseada em distância.\n",
    "# Forneça estas perguntas alternativas separadas por quebras de linha.\n",
    "# Responda apenas com os textos das perguntas, sem introdução ou comentários finais. Não coloque bullets ou numeros nas linhas.\n",
    "# Pergunta original: {question}\n",
    "# Perguntas:\"\"\"\n",
    "\n",
    "# multi_query_prompt = PromptTemplate.from_template(multi_query_prompt_template)\n",
    "\n",
    "# multi_query_chain = multi_query_prompt | query_model | CommaSeparatedListOutputParser()\n",
    "\n",
    "# multi_query_retriever = MultiQueryRetriever(\n",
    "#     retriever=vector_store.as_retriever(), llm_chain=multi_query_chain, \n",
    "# )\n",
    "\n",
    "hyde_prompt_template = \"\"\"\n",
    "Escreva uma frase que possa responder à pergunta apresentada. Não adicione mais nada.\n",
    "Pergunta: {query}\n",
    "Frase:\n",
    "\"\"\"\n",
    "\n",
    "hyde_prompt = PromptTemplate.from_template(hyde_prompt_template)\n",
    "# Next, build the HyDE chain:\n",
    "hyde_chain = hyde_prompt | query_model | StrOutputParser() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fd1904",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_model = OllamaLLM(model=\"granite3.3:8b\")\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_messages(\n",
    "    [ \n",
    "        (\"system\", \"Responda usando exclusivamente os conteúdo fornecido. Seja breve na resposta com no máximo 100 palavras.\\n\\nContexto:\\n{contexto}\"),\n",
    "        (\"human\", \"{query}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "cadeia = (\n",
    "    {\n",
    "        \"contexto\": {\"query\": RunnablePassthrough()} | hyde_chain | vector_store.as_retriever(), \n",
    "        \"query\": RunnablePassthrough(),#B\n",
    "    }\n",
    "    | rag_prompt \n",
    "    | question_model \n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53032855",
   "metadata": {},
   "outputs": [],
   "source": [
    "cadeia.invoke(\"Como fazer um seguro viagem?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd95f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cadeia.invoke(\"O que fazer se tiver meu cartão Gold roubado?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2733693b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "# Define application steps\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(hyde_chain.invoke(state[\"question\"]))\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = rag_prompt.invoke({\"query\": state[\"question\"], \"contexto\": docs_content})\n",
    "    response = question_model.invoke(messages)\n",
    "    return {\"answer\": response}\n",
    "\n",
    "\n",
    "# Compile application and test\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5214d31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.invoke({\"question\": \"Quais os beneficios de um cartão platinum?\" })['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb756e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Define your desired data structure.\n",
    "class QandA(BaseModel):\n",
    "    question: str = Field(description=\"question\")\n",
    "    answer: str = Field(description=\"answer to the question\")\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "modelo = ChatOpenAI(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# And a query intented to prompt a language model to populate the data structure.\n",
    "joke_query = \"Tell me a joke.\"\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = JsonOutputParser(pydantic_object=QandA)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Com base no conteúdo fornecido, crie duas perguntas, uma em cada linha, sem marcador ou numeração.\\n\\nConteúdo: {content}\\n\",\n",
    "    input_variables=[\"content\"],\n",
    "    # partial_variables={\"format_instructions\": QandA.model_json_schema()},\n",
    ")\n",
    "\n",
    "chain = prompt | modelo | StrOutputParser()\n",
    "\n",
    "# perguntas = chain.batch([p.page_content for p in pedacos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d401f5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "perguntas_respostas = []\n",
    "\n",
    "resposta_prompt = PromptTemplate(\n",
    "    template=\"Com base no conteúdo fornecido, responda a pergunda em no máximo duas frases.\\n\\nConteúdo: {content}\\n\\nPergunta: {pergunta}\\n\\nResposta:\",\n",
    "    input_variables=[\"content\", \"pergunta\"],\n",
    "    # partial_variables={\"format_instructions\": QandA.model_json_schema()},\n",
    ")\n",
    "\n",
    "resposta_chain = resposta_prompt | modelo | StrOutputParser()\n",
    "\n",
    "for i in range(len(pedacos)):\n",
    "    for pergunta in perguntas[i].split(\"\\n\"):\n",
    "        print(pergunta)\n",
    "        perguntas_respostas.append({\"pergunta\": pergunta.strip(), \"resposta\": resposta_chain.invoke({\"content\": pedacos[i].page_content, \"pergunta\": pergunta.strip()})})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a96227",
   "metadata": {},
   "outputs": [],
   "source": [
    "perguntas_respostas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de0d674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"test_qa.json\", \"w\", encoding=\"utf-8\") as file:\n",
    "    json.dump(perguntas_respostas, file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000d244a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.evaluation.qa import QAGenerateChain\n",
    "\n",
    "# Initialize the LLM for generating Q&A pairs\n",
    "example_gen_chain = QAGenerateChain.from_llm(modelo)\n",
    "\n",
    "# Generate Q&A pairs from the documents\n",
    "# The input to apply_and_parse should be a list of dictionaries, \n",
    "# where each dictionary contains a 'doc' key with the text content.\n",
    "new_examples = example_gen_chain.apply_and_parse(\n",
    "    [{\"doc\": t.page_content} for t in pedacos]\n",
    ")\n",
    "\n",
    "# Print the generated examples\n",
    "# for example in new_examples:\n",
    "#     print(f\"Query: {example['query']}\")\n",
    "#     print(f\"Answer: {example['answer']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0d6459",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"qa_pairs.json\", \"w\", encoding=\"utf-8\") as file:\n",
    "    json.dump(new_examples, file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dbe614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "with open(\"qa_pairs.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    new_examples = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab85925",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\n",
    "        \"contexto\": {\"query\": RunnablePassthrough()} | hyde_chain | vector_store.as_retriever(), \n",
    "        \"query\": RunnablePassthrough(),#B\n",
    "    }\n",
    "    | rag_prompt \n",
    "    | modelo \n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "eval_data = [{\"query\": pair[\"qa_pairs\"][\"query\"], \"answer\": pair[\"qa_pairs\"][\"answer\"] } for pair in new_examples]\n",
    "\n",
    "eval_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108eae8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = chain.batch(eval_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4a0430",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8274fbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.evaluation.qa import QAEvalChain\n",
    "eval_chain = QAEvalChain.from_llm(modelo)\n",
    "graded_outputs = eval_chain.evaluate(eval_data, [ {\"result\": p } for p in predictions ])\n",
    "graded_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ed78e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrects = 0\n",
    "for i, eg in enumerate(eval_data):\n",
    "    # print(f\"Example {i}:\")\n",
    "    # print(\"Question: \" + eval_data[i]['query'])\n",
    "    # print(\"Real Answer: \" + eval_data[i]['answer'])\n",
    "    # print(\"Predicted Answer: \" + predictions[i])\n",
    "    # (\"Predicted Grade: \" + graded_outputs[i]['results'].split(\"\\n\")[-1].split(\":\")[-1].strip())\n",
    "    corrects = corrects + (1 if graded_outputs[i]['results'].split(\"\\n\")[-1].split(\":\")[-1].strip() == \"CORRECT\" else 0)\n",
    "    # print()\n",
    "    \n",
    "corrects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab534cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrects / len(eval_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
